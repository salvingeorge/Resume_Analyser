{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\salvin\\anaconda3\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\salvin\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: spacy in c:\\users\\salvin\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (1.24.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from PyPDF2) (4.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\salvin\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\salvin\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\salvin\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\salvin\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\salvin\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\salvin\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from seaborn) (1.9.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\salvin\\anaconda3\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: fasttext in c:\\users\\salvin\\anaconda3\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from fasttext) (2.11.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from fasttext) (63.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from fasttext) (1.24.4)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (63.4.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "     ---------------------------------------- 42.8/42.8 MB 9.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from en-core-web-md==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (63.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.64.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.24.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "Requirement already satisfied: transformers in c:\\users\\salvin\\anaconda3\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: requests in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvin\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'torchvision\\xa0torchaudio'\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud \n",
    "!pip install nltk \n",
    "!pip install spacy \n",
    "!pip install PyPDF2 \n",
    "!pip install scikit-learn \n",
    "!pip install gensim \n",
    "!pip install joblib \n",
    "!pip install pandas \n",
    "!pip install matplotlib \n",
    "!pip install seaborn \n",
    "!pip install numpy\n",
    "!pip install fasttext\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md\n",
    "!pip install transformers\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import PyPDF2\n",
    "import io\n",
    "import sys\n",
    "from spacy.matcher import Matcher\n",
    "import spacy\n",
    "from PyPDF2 import PdfReader\n",
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    loaded_mwe_list = []\n",
    "    with open('data/mwe_list.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            loaded_mwe_list.append(tuple(line.strip().split()))\n",
    "    # Define multi-word expressions\n",
    "    mwe_list = loaded_mwe_list\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    # MWETokenizer\n",
    "    mwe_tokenizer = MWETokenizer(mwe_list, separator='_')\n",
    "    \n",
    "    # First tokenize to single words\n",
    "    single_word_tokens = word_tokenize(text)\n",
    "\n",
    "    # Then use MWETokenizer\n",
    "    tokens = mwe_tokenizer.tokenize(single_word_tokens)\n",
    "\n",
    "    # Stopwords removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "def extract_skills_backup(skills_per_category, processed_text_from_spacy):\n",
    "    # Load spaCy model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Convert the processed_text_from_spacy string to a spaCy Doc object\n",
    "    doc = nlp(processed_text_from_spacy)\n",
    "\n",
    "    # Extract skills using spaCy Matcher and skills dictionary\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Create patterns from skills dictionary\n",
    "    for category, category_skills in skills_per_category.items():\n",
    "        for skill in category_skills:\n",
    "            pattern = [{\"LOWER\": token.lower()} for token in skill.split()]\n",
    "            matcher.add(category + \"_\" + skill.replace(\" \", \"_\"), [pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    matched_skills = []\n",
    "    seen_skills = set()  # To keep track of unique skills\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        skill_text = doc[start:end].text.split(\"_\")[1] if \"_\" in doc[start:end].text else doc[start:end].text\n",
    "        if skill_text not in seen_skills:\n",
    "            matched_skills.append(skill_text)\n",
    "            seen_skills.add(skill_text)\n",
    "    return matched_skills\n",
    "\n",
    "resume_text = df['Resume'][0]\n",
    "\n",
    "processed_text = preprocess_text(resume_text)\n",
    "preprocessed_teXt_str = ' '.join(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted skills are: ['flask', 'cassandra', 'hbase', 'programming', 'docker', 'numpy', 'database', 'html', 'coding', 'angular', 'classification', 'mysql', 'indexing', 'git', 'java', 'javascript', 'python', 'erp', 'matplotlib', 'kafka', 'bootstrap', 'sql', 'word', 'tableau']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: â¢ Proficient in MS office (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_skills(text):\n",
    "    # Example skill set (you would expand this list)\n",
    "    \n",
    "    # Load the list from the text file\n",
    "    loaded_skills = []\n",
    "    with open('data/predefined_skills.txt', 'r') as file:\n",
    "        predefined_skills = [line.strip() for line in file]\n",
    "\n",
    "    # Verify the loaded data\n",
    "    predefined_skills_lowered = [skill.lower() for skill in predefined_skills]\n",
    "    # print('Preprecessed lowered: ',predefined_skills_lowered)\n",
    "    \n",
    "    skills = []\n",
    "\n",
    "    for word in text:\n",
    "        if word in predefined_skills_lowered:\n",
    "            skills.append(word)\n",
    "\n",
    "    return list(set(skills))\n",
    "\n",
    "skills = extract_skills(processed_text)\n",
    "print(\"The extracted skills are:\", skills)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['processed'] = df['Resume'].apply(preprocess_text)\n",
    "df['Skills'] = df['processed'].apply(extract_skills)\n",
    "\n",
    "df['Skills_non_list'] = df['Skills'].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_extract_text(pdf_path):\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf_reader = PdfReader(f)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        text = \"\"\n",
    "        \n",
    "        for page in range(num_pages):\n",
    "            pdf_page = pdf_reader.pages[page]\n",
    "            text += pdf_page.extract_text()\n",
    "            \n",
    "    # Remove all non-alphanumeric characters except space and new line\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\n]+', '', text)\n",
    "    cleaned_text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Extract Name\n",
    "    # Now let's use spaCy to extract the names\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(cleaned_text)\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Doe  555 5555555  janedoeemailcom  123 Main Street Anytown CA 12345     Summary     Highly motivated and experienced data scientist with a proven track record of success in developing  and implementing data driven solutions for a variety of businesses Expertise in machine learning  statistical analysis and data visualization Passionate about using data to drive business insights and  improve decision making     Skills     Programming Languages Python R Java SQL   Machine Learning Algorithms Linear regression logistic regression random forests support vector  machines   Statistical Methods Hypothesis testing regression analysis ANOVA   Data Visualization Tools Tableau Power BI Matplotlib Seaborn   Experience     Data Scientist  Google  Mountain View CA  2020  Present     Developed and implemented machine learning models to predict user behavior and improve product  engagement   Performed data analysis to identify trends and patterns in user data   Created data visualizations to communicate insights to product managers and engineers   Collaborated with cross functional teams to develop and implement data driven product features   Data Analyst  Facebook  Menlo Park CA  2018  2020     Collected cleaned and analyzed large datasets to extract meaningful insights   Prepared reports and presentations to communicate findings to marketing and product teams   Developed and maintained data dashboards to track key performance indicators   Provided support to other departments with data related needs   Education    Master of Science in Data Science  Stanford University  Stanford CA  2018     Thesis A Machine Learning Approach to Predicting User Churn in Social Media Platforms   Bachelor of Arts in Mathematics  University of California Berkeley  Berkeley CA  2016     Projects     Developed a machine learning model to predict stock prices using historical data   Created a data visualization dashboard to track the performance of a portfolio of stocks   Performed sentiment analysis on social media data to understand public opinion about a particular  company   Awards and Recognition     Deans List Stanford University   Undergraduate Research Award University of California Berkeley   Data Science Hackathon Winner Google   References     Available upon request  \n"
     ]
    }
   ],
   "source": [
    "cleaned_resume = clean_and_extract_text(r\"TESTING/Jane Doe - Data Scientist.pdf\")\n",
    "\n",
    "print(cleaned_resume)\n",
    "preprocessed_test = preprocess_text(cleaned_resume)\n",
    "skills_test = extract_skills(preprocessed_test)\n",
    "preprocessed_test_str = ' '.join(preprocessed_test)\n",
    "skills_test_str = ' '.join(skills_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning statistical analysis data visualization Python R Java SQL Machine Learning regression analysis Data Visualization Tableau Power BI Matplotlib data analysis Data Science'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load from the text file\n",
    "with open('data/skills_per_category_dict.txt', 'r') as file:\n",
    "    skills_per_category = json.load(file)\n",
    "\n",
    "def extract_skills_backup(skills_per_category, processed_text_from_spacy):\n",
    "    # Load spaCy model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Convert the processed_text_from_spacy string to a spaCy Doc object\n",
    "    doc = nlp(processed_text_from_spacy)\n",
    "\n",
    "    # Extract skills using spaCy Matcher and skills dictionary\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Create patterns from skills dictionary\n",
    "    for category, category_skills in skills_per_category.items():\n",
    "        for skill in category_skills:\n",
    "            pattern = [{\"LOWER\": token.lower()} for token in skill.split()]\n",
    "            matcher.add(category + \"_\" + skill.replace(\" \", \"_\"), [pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    matched_skills = []\n",
    "    seen_skills = set()  # To keep track of unique skills\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        skill_text = doc[start:end].text.split(\"_\")[1] if \"_\" in doc[start:end].text else doc[start:end].text\n",
    "        if skill_text not in seen_skills:\n",
    "            matched_skills.append(skill_text)\n",
    "            seen_skills.add(skill_text)\n",
    "    return matched_skills\n",
    "\n",
    "skills_test = extract_skills_backup(skills_per_category,cleaned_resume)\n",
    "\n",
    "skills_test = ' '.join(skills_test)\n",
    "skills_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction through Word2Vec Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map category ID to category name\n",
    "category_mapping = {\n",
    "    15: \"Java Developer\",\n",
    "    23: \"Testing\",\n",
    "    8: \"DevOps Engineer\",\n",
    "    20: \"Python Developer\",\n",
    "    24: \"Web Designing\",\n",
    "    12: \"HR\",\n",
    "    13: \"Hadoop\",\n",
    "    3: \"Blockchain\",\n",
    "    10: \"ETL Developer\",\n",
    "    18: \"Operations Manager\",\n",
    "    6: \"Data Science\",\n",
    "    22: \"Sales\",\n",
    "    16: \"Mechanical Engineer\",\n",
    "    1: \"Arts\",\n",
    "    7: \"Database\",\n",
    "    11: \"Electrical Engineering\",\n",
    "    14: \"Health and fitness\",\n",
    "    19: \"PMO\",\n",
    "    4: \"Business Analyst\",\n",
    "    9: \"DotNet Developer\",\n",
    "    2: \"Automation Testing\",\n",
    "    17: \"Network Security Engineer\",\n",
    "    21: \"SAP Developer\",\n",
    "    5: \"Civil Engineer\",\n",
    "    0: \"Advocate\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When compared directly with resume text (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.694300518134715\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       0.17      0.25      0.20         4\n",
      "                     Arts       0.50      0.43      0.46         7\n",
      "       Automation Testing       0.60      0.60      0.60         5\n",
      "               Blockchain       1.00      0.50      0.67         8\n",
      "         Business Analyst       0.67      0.33      0.44         6\n",
      "           Civil Engineer       1.00      0.20      0.33         5\n",
      "             Data Science       0.86      0.75      0.80         8\n",
      "                 Database       0.88      1.00      0.93         7\n",
      "          DevOps Engineer       1.00      0.91      0.95        11\n",
      "         DotNet Developer       0.00      0.00      0.00         5\n",
      "            ETL Developer       0.89      1.00      0.94         8\n",
      "   Electrical Engineering       0.60      1.00      0.75         6\n",
      "                       HR       1.00      0.56      0.71         9\n",
      "                   Hadoop       0.80      1.00      0.89         8\n",
      "       Health and fitness       0.67      0.67      0.67         6\n",
      "           Java Developer       0.67      0.94      0.78        17\n",
      "      Mechanical Engineer       0.50      0.38      0.43         8\n",
      "Network Security Engineer       1.00      0.60      0.75         5\n",
      "       Operations Manager       0.44      1.00      0.62         8\n",
      "                      PMO       0.57      0.67      0.62         6\n",
      "         Python Developer       0.73      0.80      0.76        10\n",
      "            SAP Developer       1.00      0.20      0.33         5\n",
      "                    Sales       1.00      0.62      0.77         8\n",
      "                  Testing       0.70      1.00      0.82        14\n",
      "            Web Designing       0.80      0.44      0.57         9\n",
      "\n",
      "                 accuracy                           0.69       193\n",
      "                macro avg       0.72      0.63      0.63       193\n",
      "             weighted avg       0.74      0.69      0.68       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Assume df is your DataFrame containing 'Resume' and 'Category' columns\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_resume = df['Resume'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_resume, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the vector representation of a document\n",
    "def get_vector(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return None\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    return sum(vectors) / len(vectors) if vectors else None\n",
    "\n",
    "# Apply Word2Vec to each resume\n",
    "df['Word2Vec'] = df['Resume'].apply(lambda x: get_vector(x.split()))\n",
    "\n",
    "# Drop rows with missing Word2Vec representations\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"data/word2vec_model.bin\")\n",
    "\n",
    "# Prepare data for training\n",
    "X = pd.DataFrame(df['Word2Vec'].tolist())\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# SVM with Word2Vec and probability estimates\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_word2vec_svm = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_word2vec_svm)\n",
    "\n",
    "# Decode integer labels back to original class names\n",
    "y_test_original_classes = le.inverse_transform(y_test)\n",
    "y_pred_original_classes = le.inverse_transform(y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original_classes, y_pred_original_classes))\n",
    "\n",
    "# Save the SVM model\n",
    "pickle.dump(svm_model, open('data/svm_model_word2vec_resume.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Advocate: 0.33\n",
      "Electrical Engineering: 0.11\n",
      "HR: 0.11\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load both the SVM model and Word2Vec model\n",
    "svm_model = joblib.load('data/svm_model_word2vec_resume.pkl')\n",
    "word2vec_model = Word2Vec.load('data/word2vec_model.bin')  # Replace 'word2vec_model.bin' with the actual file name of your Word2Vec model\n",
    "\n",
    "# Assuming you have a pre-defined tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer.fit(df['Resume'])\n",
    "\n",
    "\n",
    "\n",
    "def predict_top3_categories(text, model, word2vec_model):\n",
    "    # Tokenize the text data\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Get the vector representation of the document using Word2Vec\n",
    "    vector = get_vector(tokens)\n",
    "\n",
    "    # Reshape the vector to match the input format of the SVM classifier\n",
    "    vector = np.array(vector).reshape(1, -1)\n",
    "\n",
    "    # Make probability predictions using the SVM classifier\n",
    "    probabilities = model.predict_proba(vector)[0]\n",
    "\n",
    "    # Get the indices of the top 3 predicted categories\n",
    "    top3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "\n",
    "    # Map category IDs to category names and probabilities\n",
    "    top3_predictions = [(category_mapping.get(idx, \"Unknown\"), probabilities[idx]) for idx in top3_indices]\n",
    "\n",
    "    return top3_predictions\n",
    "\n",
    "# Example usage\n",
    "top3_predictions = predict_top3_categories(preprocessed_test_str, svm_model, word2vec_model)\n",
    "print(\"Top 3 Predictions:\")\n",
    "for category, probability in top3_predictions:\n",
    "    print(f\"{category}: {probability:.2f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When compared directly with the Skills extracted (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13966480446927373\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.75      0.60      0.67         5\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.00      0.00      0.00        11\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         6\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.13      1.00      0.23        17\n",
      "          16       0.12      0.62      0.21         8\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         8\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00        10\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         8\n",
      "          23       0.00      0.00      0.00        14\n",
      "          24       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.14       179\n",
      "   macro avg       0.04      0.09      0.04       179\n",
      "weighted avg       0.04      0.14      0.05       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Assume df is your DataFrame containing 'Resume' and 'Category' columns\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_resume = df['Skills_non_list'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_resume, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the vector representation of a document\n",
    "def get_vector(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return None\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    return sum(vectors) / len(vectors) if vectors else None\n",
    "\n",
    "# Apply Word2Vec to each resume\n",
    "df['Word2Vec'] = df['Skills_non_list'].apply(lambda x: get_vector(x.split()))\n",
    "\n",
    "# Drop rows with missing Word2Vec representations\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"data/word2vec_model.bin\")\n",
    "\n",
    "# Prepare data for training\n",
    "X = pd.DataFrame(df['Word2Vec'].tolist())\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# SVM with Word2Vec and probability estimates\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_word2vec_svm = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_word2vec_svm)\n",
    "\n",
    "# Decode integer labels back to original class names\n",
    "y_test_original_classes = le.inverse_transform(y_test)\n",
    "y_pred_original_classes = le.inverse_transform(y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original_classes, y_pred_original_classes))\n",
    "\n",
    "# Save the SVM model\n",
    "pickle.dump(svm_model, open('data/svm_model_word2vec_resume.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Java Developer: 0.10\n",
      "Hadoop: 0.10\n",
      "Python Developer: 0.09\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load both the SVM model and Word2Vec model\n",
    "svm_model = joblib.load('data/svm_model_word2vec_resume.pkl')\n",
    "word2vec_model = Word2Vec.load('data/word2vec_model.bin') \n",
    "\n",
    "\n",
    "def predict_top3_categories(text, model, word2vec_model):\n",
    "    # Tokenize the text data\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Get the vector representation of the document using Word2Vec\n",
    "    vector = get_vector(tokens)\n",
    "\n",
    "    # Reshape the vector to match the input format of the SVM classifier\n",
    "    vector = np.array(vector).reshape(1, -1)\n",
    "\n",
    "    # Make probability predictions using the SVM classifier\n",
    "    probabilities = model.predict_proba(vector)[0]\n",
    "\n",
    "    # Get the indices of the top 3 predicted categories\n",
    "    top3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "\n",
    "    # Map category IDs to category names and probabilities\n",
    "    top3_predictions = [(category_mapping.get(idx, \"Unknown\"), probabilities[idx]) for idx in top3_indices]\n",
    "\n",
    "    return top3_predictions\n",
    "\n",
    "\n",
    "top3_predictions = predict_top3_categories(preprocessed_test_str, svm_model, word2vec_model)\n",
    "print(\"Top 3 Predictions:\")\n",
    "for category, probability in top3_predictions:\n",
    "    print(f\"{category}: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill when compared with Word2Vec(random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9832402234636871\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         8\n",
      "           7       0.88      1.00      0.93         7\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      0.60      0.75         5\n",
      "          15       1.00      1.00      1.00        17\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       0.80      1.00      0.89         8\n",
      "          23       1.00      1.00      1.00        14\n",
      "          24       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.98       179\n",
      "   macro avg       0.99      0.98      0.98       179\n",
      "weighted avg       0.99      0.98      0.98       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Assume df is your DataFrame containing 'Skills_non_list' and 'Category' columns\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_skills = df['Skills_non_list'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_skills, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the vector representation of a document\n",
    "def get_vector(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return None\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    return sum(vectors) / len(vectors) if vectors else None\n",
    "\n",
    "# Apply Word2Vec to each set of skills\n",
    "df['Word2Vec'] = df['Skills_non_list'].apply(lambda x: get_vector(x.split()))\n",
    "\n",
    "# Drop rows with missing Word2Vec representations\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"data/word2vec_model_skills.bin\")\n",
    "\n",
    "# Prepare data for training\n",
    "X = pd.DataFrame(df['Word2Vec'].tolist())\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_word2vec_rf = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_word2vec_rf)\n",
    "\n",
    "# Decode integer labels back to original class names\n",
    "y_test_original_classes = le.inverse_transform(y_test)\n",
    "y_pred_original_classes = le.inverse_transform(y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original_classes, y_pred_original_classes))\n",
    "\n",
    "# Save the Random Forest model\n",
    "pickle.dump(rf_classifier, open('data/random_forest_classifier_model_word2vec_skills.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Java Developer: 0.29\n",
      "Python Developer: 0.14\n",
      "DevOps Engineer: 0.10\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load both the SVM model and Word2Vec model\n",
    "svm_model = joblib.load('data/random_forest_classifier_model_word2vec_skills.pkl')\n",
    "word2vec_model = Word2Vec.load('data/word2vec_model.bin')\n",
    "\n",
    "# Assuming preprocessed_test_str is your new text for testing\n",
    "# Tokenize the text data\n",
    "tokens = preprocessed_test_str.split()\n",
    "\n",
    "# Get the vector representation of the document using Word2Vec\n",
    "vector = get_vector(tokens)\n",
    "\n",
    "# Reshape the vector to match the input format of the SVM classifier\n",
    "vector = np.array(vector).reshape(1, -1)\n",
    "\n",
    "# Make probability predictions using the SVM classifier\n",
    "probabilities = svm_model.predict_proba(vector)[0]\n",
    "\n",
    "# Get the indices of the top 3 predicted categories\n",
    "top3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "\n",
    "# Map category IDs to category names and probabilities\n",
    "top3_predictions = [(category_mapping.get(idx, \"Unknown\"), probabilities[idx]) for idx in top3_indices]\n",
    "\n",
    "print(\"Top 3 Predictions:\")\n",
    "for category, probability in top3_predictions:\n",
    "    print(f\"{category}: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume when compared with Word2Vec(random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994413407821229\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         8\n",
      "           7       1.00      1.00      1.00         7\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00        17\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        14\n",
      "          24       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.99       179\n",
      "   macro avg       0.99      1.00      0.99       179\n",
      "weighted avg       1.00      0.99      0.99       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_skills = df['Resume'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_skills, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the vector representation of a document\n",
    "def get_vector(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return None\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    return sum(vectors) / len(vectors) if vectors else None\n",
    "\n",
    "# Apply Word2Vec to each set of skills\n",
    "df['Word2Vec'] = df['Resume'].apply(lambda x: get_vector(x.split()))\n",
    "\n",
    "# Drop rows with missing Word2Vec representations\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"data/word2vec_model_resume.bin\")\n",
    "\n",
    "# Prepare data for training\n",
    "X = pd.DataFrame(df['Word2Vec'].tolist())\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_word2vec_rf = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_word2vec_rf)\n",
    "\n",
    "# Decode integer labels back to original class names\n",
    "y_test_original_classes = le.inverse_transform(y_test)\n",
    "y_pred_original_classes = le.inverse_transform(y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original_classes, y_pred_original_classes))\n",
    "\n",
    "# Save the Random Forest model\n",
    "pickle.dump(rf_classifier, open('data/random_forest_classifier_model_word2vec_resume.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Data Science: 0.22\n",
      "Arts: 0.11\n",
      "Advocate: 0.09\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load both the SVM model and Word2Vec model\n",
    "svm_model = joblib.load('data/random_forest_classifier_model_word2vec_resume.pkl')\n",
    "word2vec_model = Word2Vec.load('data/word2vec_model.bin')\n",
    "\n",
    "\n",
    "# Tokenize the text data\n",
    "tokens = preprocessed_test_str.split()\n",
    "\n",
    "# Get the vector representation of the document using Word2Vec\n",
    "vector = get_vector(tokens)\n",
    "\n",
    "# Reshape the vector to match the input format of the SVM classifier\n",
    "vector = np.array(vector).reshape(1, -1)\n",
    "\n",
    "# Make probability predictions using the SVM classifier\n",
    "probabilities = svm_model.predict_proba(vector)[0]\n",
    "\n",
    "# Get the indices of the top 3 predicted categories\n",
    "top3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "\n",
    "# Map category IDs to category names and probabilities\n",
    "top3_predictions = [(category_mapping.get(idx, \"Unknown\"), probabilities[idx]) for idx in top3_indices]\n",
    "\n",
    "print(\"Top 3 Predictions:\")\n",
    "for category, probability in top3_predictions:\n",
    "    print(f\"{category}: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume when compared with Word2Vec(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9162011173184358\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.83      1.00      0.91         5\n",
      "           2       0.75      0.60      0.67         5\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.83      0.83      0.83         6\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      0.75      0.86         8\n",
      "           7       1.00      0.71      0.83         7\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       1.00      0.60      0.75         5\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       0.80      1.00      0.89         8\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       0.77      1.00      0.87        17\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       0.71      1.00      0.83         5\n",
      "          18       0.89      1.00      0.94         8\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       0.83      1.00      0.91        10\n",
      "          21       1.00      0.40      0.57         5\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        14\n",
      "          24       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.92       179\n",
      "   macro avg       0.90      0.87      0.87       179\n",
      "weighted avg       0.92      0.92      0.91       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_skills = df['Resume'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_skills, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the vector representation of a document\n",
    "def get_vector(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return None\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    return sum(vectors) / len(vectors) if vectors else None\n",
    "\n",
    "# Apply Word2Vec to each set of skills\n",
    "df['Word2Vec'] = df['Resume'].apply(lambda x: get_vector(x.split()))\n",
    "\n",
    "# Drop rows with missing Word2Vec representations\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"data/word2vec_model_resume.bin\")\n",
    "\n",
    "# Prepare data for training\n",
    "X = pd.DataFrame(df['Word2Vec'].tolist())\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# K-Nearest Neighbors classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (n_neighbors) as needed\n",
    "\n",
    "# Fit the model\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_word2vec_knn = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_word2vec_knn)\n",
    "\n",
    "# Decode integer labels back to original class names\n",
    "y_test_original_classes = le.inverse_transform(y_test)\n",
    "y_pred_original_classes = le.inverse_transform(y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original_classes, y_pred_original_classes))\n",
    "\n",
    "# Save the K-Nearest Neighbors model\n",
    "pickle.dump(knn_classifier, open('data/knn_classifier_model_word2vec_resume.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Data Science: 0.22\n",
      "Arts: 0.11\n",
      "Advocate: 0.09\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load both the SVM model and Word2Vec model\n",
    "knn_classifier = joblib.load('data/knn_classifier_model_word2vec_resume.pkl')\n",
    "word2vec_model = Word2Vec.load('data/word2vec_model.bin')\n",
    "\n",
    "\n",
    "# Tokenize the text data\n",
    "tokens = preprocessed_test_str.split()\n",
    "\n",
    "# Get the vector representation of the document using Word2Vec\n",
    "vector = get_vector(tokens)\n",
    "\n",
    "# Reshape the vector to match the input format of the SVM classifier\n",
    "vector = np.array(vector).reshape(1, -1)\n",
    "\n",
    "# Make probability predictions using the SVM classifier\n",
    "probabilities = svm_model.predict_proba(vector)[0]\n",
    "\n",
    "# Get the indices of the top 3 predicted categories\n",
    "top3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "\n",
    "# Map category IDs to category names and probabilities\n",
    "top3_predictions = [(category_mapping.get(idx, \"Unknown\"), probabilities[idx]) for idx in top3_indices]\n",
    "\n",
    "print(\"Top 3 Predictions:\")\n",
    "for category, probability in top3_predictions:\n",
    "    print(f\"{category}: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills when compared with TFIDF(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8938547486033519\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.83      1.00      0.91         5\n",
      "           2       0.38      0.60      0.46         5\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.62      0.83      0.71         6\n",
      "           5       0.80      1.00      0.89         4\n",
      "           6       1.00      1.00      1.00         8\n",
      "           7       0.50      0.14      0.22         7\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       0.75      0.60      0.67         5\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       0.89      1.00      0.94         8\n",
      "          14       1.00      0.60      0.75         5\n",
      "          15       0.85      1.00      0.92        17\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       0.83      1.00      0.91         5\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      0.40      0.57         5\n",
      "          22       0.80      1.00      0.89         8\n",
      "          23       1.00      1.00      1.00        14\n",
      "          24       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.89       179\n",
      "   macro avg       0.85      0.84      0.83       179\n",
      "weighted avg       0.89      0.89      0.88       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\salvin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_skills = df['Skills_non_list'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_skills, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the vector representation of a document\n",
    "def get_vector(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return None\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    return sum(vectors) / len(vectors) if vectors else None\n",
    "\n",
    "# Apply Word2Vec to each set of skills\n",
    "df['Word2Vec'] = df['Skills_non_list'].apply(lambda x: get_vector(x.split()))\n",
    "\n",
    "# Drop rows with missing Word2Vec representations\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"data/word2vec_model_skill.bin\")\n",
    "\n",
    "# Prepare data for training\n",
    "X = pd.DataFrame(df['Word2Vec'].tolist())\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# K-Nearest Neighbors classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (n_neighbors) as needed\n",
    "\n",
    "# Fit the model\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_word2vec_knn = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_word2vec_knn)\n",
    "\n",
    "# Decode integer labels back to original class names\n",
    "y_test_original_classes = le.inverse_transform(y_test)\n",
    "y_pred_original_classes = le.inverse_transform(y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original_classes, y_pred_original_classes))\n",
    "\n",
    "# Save the K-Nearest Neighbors model\n",
    "pickle.dump(knn_classifier, open('data/knn_classifier_model_word2vec_skill.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Data Science: 0.22\n",
      "Arts: 0.11\n",
      "Advocate: 0.09\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load both the SVM model and Word2Vec model\n",
    "knn_classifier = joblib.load('data/knn_classifier_model_word2vec_resume.pkl')\n",
    "word2vec_model = Word2Vec.load('data/word2vec_model.bin')\n",
    "\n",
    "\n",
    "# Tokenize the text data\n",
    "tokens = skills_test_str.split()\n",
    "\n",
    "# Get the vector representation of the document using Word2Vec\n",
    "vector = get_vector(tokens)\n",
    "\n",
    "# Reshape the vector to match the input format of the SVM classifier\n",
    "vector = np.array(vector).reshape(1, -1)\n",
    "\n",
    "# Make probability predictions using the SVM classifier\n",
    "probabilities = svm_model.predict_proba(vector)[0]\n",
    "\n",
    "# Get the indices of the top 3 predicted categories\n",
    "top3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "\n",
    "# Map category IDs to category names and probabilities\n",
    "top3_predictions = [(category_mapping.get(idx, \"Unknown\"), probabilities[idx]) for idx in top3_indices]\n",
    "\n",
    "print(\"Top 3 Predictions:\")\n",
    "for category, probability in top3_predictions:\n",
    "    print(f\"{category}: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classifiers = ['SVM', 'Random Forest', 'k-nearest neighbors']\n",
    "accuracy = [0.13, 0.98, 0.91]\n",
    "precision = [0.04, 0.99, 0.91]\n",
    "recall = [0.13, 0.98, 0.92]\n",
    "f1_score = [0.05, 0.98, 0.91]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0, 0].bar(classifiers, accuracy, color=['red', 'green', 'blue'])\n",
    "axs[0, 0].set_title('Accuracy')\n",
    "\n",
    "# Plot precision\n",
    "axs[0, 1].bar(classifiers, precision, color=['red', 'green', 'blue'])\n",
    "axs[0, 1].set_title('Precision')\n",
    "\n",
    "# Plot recall\n",
    "axs[1, 0].bar(classifiers, recall, color=['red', 'green', 'blue'])\n",
    "axs[1, 0].set_title('Recall')\n",
    "\n",
    "# Plot f1-score\n",
    "axs[1, 1].bar(classifiers, f1_score, color=['red', 'green', 'blue'])\n",
    "axs[1, 1].set_title('F1-Score')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
